{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "X = data.drop(columns=[\"Id\", \"SalePrice\"])\n",
    "y = data[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220\n",
      "31\n",
      "52\n",
      "114\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for type in [\"1Fam\", \"2fmCon\", \"Duplex\", \"TwnhsE\", \"TwnhsI\"]:\n",
    "  print((X[\"BldgType\"] == type).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>150.0</td>\n",
       "      <td>215245</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR3</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164660</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115149</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "249          50       RL          NaN   159000   Pave   NaN      IR2   \n",
       "313          20       RL        150.0   215245   Pave   NaN      IR3   \n",
       "335         190       RL          NaN   164660   Grvl   NaN      IR1   \n",
       "706          20       RL          NaN   115149   Pave   NaN      IR2   \n",
       "\n",
       "    LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\n",
       "249         Low    AllPub   CulDSac  ...           0        0    NaN   NaN   \n",
       "313         Low    AllPub    Inside  ...           0        0    NaN   NaN   \n",
       "335         HLS    AllPub    Corner  ...           0        0    NaN   NaN   \n",
       "706         Low    AllPub   CulDSac  ...           0        0    NaN   NaN   \n",
       "\n",
       "    MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "249        Shed     500       6    2007        WD         Normal  \n",
       "313         NaN       0       6    2009        WD         Normal  \n",
       "335        Shed     700       8    2008        WD         Normal  \n",
       "706         NaN       0       6    2007        WD         Normal  \n",
       "\n",
       "[4 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_outliers = X[X[\"LotArea\"] > 100000]\n",
    "area_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='LotArea', ylabel='SalePrice'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=X_train[\"LotArea\"], y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy = X_train.copy()\n",
    "Xy[\"SalePrice\"] = y_train\n",
    "outliers = Xy[(Xy[\"LotArea\"] > 50000) | (Xy[\"SalePrice\"] > 500000)]\n",
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n",
      "1082\n"
     ]
    }
   ],
   "source": [
    "print(len(Xy))\n",
    "Xy.drop(index=outliers.index, inplace=True)\n",
    "print(len(Xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Xy[\"SalePrice\"]\n",
    "X_train = Xy.drop(columns=\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_family_homes = X_train[X_train[\"BldgType\"] == \"2fmCon\"]\n",
    "X_train.drop(index=two_family_homes.index, inplace=True)\n",
    "y_train.drop(index=two_family_homes.index, inplace=True)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "C = data.loc[:, [\"YearBuilt\"]]\n",
    "C[\"Cluster\"] = kmeans.fit_predict(C)\n",
    "\n",
    "X_train = X_train.join(C, how=\"left\", lsuffix=\"YearBuilt\")\n",
    "X_train.drop(columns=\"YearBuilt\", inplace=True)\n",
    "X_val = X_val.join(C, how=\"left\", lsuffix=\"YearBuilt\")\n",
    "X_val.drop(columns=\"YearBuilt\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [col for col in X_train.columns if X_train[col].dtype in [\"int64\", \"float64\"]]\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "numerical_transformer = Pipeline(\n",
    "  steps=[\n",
    "    (\"imputer\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler())\n",
    "  ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "  steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "  ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"num\", numerical_transformer, numerical_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train).toarray())\n",
    "X_val = pd.DataFrame(preprocessor.transform(X_val).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    595\n",
       "2    591\n",
       "0    274\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[\"Cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 64.4562 - val_loss: 36.9312\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 29.2036 - val_loss: 23.1916\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 19.8160 - val_loss: 16.8815\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 14.9419 - val_loss: 13.1423\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 11.8924 - val_loss: 10.6409\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 9.7216 - val_loss: 8.8486\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 8.1248 - val_loss: 7.5001\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 6.9537 - val_loss: 6.4475\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 5.9920 - val_loss: 5.6069\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 5.2538 - val_loss: 4.9208\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 4.6027 - val_loss: 4.3522\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 4.0977 - val_loss: 3.8736\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 3.6723 - val_loss: 3.4670\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 3.2756 - val_loss: 3.1186\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 2.9761 - val_loss: 2.8172\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 2.6941 - val_loss: 2.5545\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 2.4298 - val_loss: 2.3253\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 2.2353 - val_loss: 2.1229\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 2.0428 - val_loss: 1.9436\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.8510 - val_loss: 1.7852\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.7039 - val_loss: 1.6436\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.5791 - val_loss: 1.5166\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.4502 - val_loss: 1.4033\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.3471 - val_loss: 1.3004\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.2550 - val_loss: 1.2075\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.1668 - val_loss: 1.1236\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.0926 - val_loss: 1.0471\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.0112 - val_loss: 0.9777\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.9455 - val_loss: 0.9141\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.8917 - val_loss: 0.8560\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.8359 - val_loss: 0.8029\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.7955 - val_loss: 0.7538\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.7352 - val_loss: 0.7092\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6910 - val_loss: 0.6684\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6549 - val_loss: 0.6306\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6247 - val_loss: 0.5957\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5740 - val_loss: 0.5638\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5570 - val_loss: 0.5340\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5174 - val_loss: 0.5068\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5061 - val_loss: 0.4814\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4822 - val_loss: 0.4575\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4595 - val_loss: 0.4354\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.4329 - val_loss: 0.4151\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.4139 - val_loss: 0.3963\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.4001 - val_loss: 0.3786\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3811 - val_loss: 0.3622\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3557 - val_loss: 0.3472\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3498 - val_loss: 0.3329\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3315 - val_loss: 0.3197\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3191 - val_loss: 0.3074\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3106 - val_loss: 0.2957\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3024 - val_loss: 0.2846\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.2976 - val_loss: 0.2743\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2809 - val_loss: 0.2648\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2611 - val_loss: 0.2561\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.2588 - val_loss: 0.2478\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2553 - val_loss: 0.2401\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.2410 - val_loss: 0.2328\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2373 - val_loss: 0.2260\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2363 - val_loss: 0.2194\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.2248 - val_loss: 0.2134\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2189 - val_loss: 0.2077\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2177 - val_loss: 0.2023\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.2132 - val_loss: 0.1972\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2033 - val_loss: 0.1924\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.2022 - val_loss: 0.1879\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1932 - val_loss: 0.1837\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1910 - val_loss: 0.1797\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1865 - val_loss: 0.1759\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1832 - val_loss: 0.1723\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1803 - val_loss: 0.1691\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1793 - val_loss: 0.1659\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1748 - val_loss: 0.1629\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1730 - val_loss: 0.1600\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1686 - val_loss: 0.1573\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1647 - val_loss: 0.1548\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1681 - val_loss: 0.1523\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1616 - val_loss: 0.1500\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1620 - val_loss: 0.1477\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1588 - val_loss: 0.1456\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1592 - val_loss: 0.1436\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1526 - val_loss: 0.1417\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1542 - val_loss: 0.1399\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1569 - val_loss: 0.1382\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1496 - val_loss: 0.1366\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1468 - val_loss: 0.1351\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1443 - val_loss: 0.1336\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1468 - val_loss: 0.1322\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1466 - val_loss: 0.1309\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1395 - val_loss: 0.1296\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1415 - val_loss: 0.1284\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1378 - val_loss: 0.1272\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1376 - val_loss: 0.1261\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1346 - val_loss: 0.1250\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1358 - val_loss: 0.1240\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1344 - val_loss: 0.1231\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1353 - val_loss: 0.1221\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1327 - val_loss: 0.1212\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1348 - val_loss: 0.1203\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.1335 - val_loss: 0.1195\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1305 - val_loss: 0.1186\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1294 - val_loss: 0.1179\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1289 - val_loss: 0.1171\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1285 - val_loss: 0.1164\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1317 - val_loss: 0.1157\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.1271 - val_loss: 0.1151\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1294 - val_loss: 0.1144\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1267 - val_loss: 0.1137\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1261 - val_loss: 0.1131\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1303 - val_loss: 0.1125\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1243 - val_loss: 0.1119\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1256 - val_loss: 0.1113\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1254 - val_loss: 0.1108\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1182 - val_loss: 0.1102\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1245 - val_loss: 0.1097\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.1234 - val_loss: 0.1092\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.1238 - val_loss: 0.1087\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1235 - val_loss: 0.1082\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1233 - val_loss: 0.1077\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1230 - val_loss: 0.1072\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1173 - val_loss: 0.1068\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.1189 - val_loss: 0.1064\n",
      "Epoch 123/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1216 - val_loss: 0.1059\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1200 - val_loss: 0.1055\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1174 - val_loss: 0.1051\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.1178 - val_loss: 0.1047\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1186 - val_loss: 0.1043\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1198 - val_loss: 0.1039\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1199 - val_loss: 0.1035\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1203 - val_loss: 0.1031\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1116 - val_loss: 0.1028\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1182 - val_loss: 0.1024\n",
      "Epoch 133/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1173 - val_loss: 0.1021\n",
      "Epoch 134/1000\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.1148 - val_loss: 0.1017\n",
      "Epoch 135/1000\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1168 - val_loss: 0.1014\n",
      "Epoch 136/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.1172 - val_loss: 0.1010\n",
      "Epoch 137/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.1156 - val_loss: 0.1007\n",
      "Epoch 138/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.1092 - val_loss: 0.1004\n",
      "Epoch 139/1000\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 0.1147"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\house prices regression\\deep_learning.ipynb KomÃ³rka 13\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m callbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     min_delta\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m   optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m   loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_logarithmic_error\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m   \u001b[39m#X, y,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m   X_train, y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m   validation_data\u001b[39m=\u001b[39;49m(X_val, y_val),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m   batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[early_stopping],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m   verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Desktop/projekty/ml/house%20prices%20regression/deep_learning.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\engine\\training.py:1460\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1457\u001b[0m   val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m   1458\u001b[0m   epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1460\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[0;32m   1461\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[0;32m   1462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\callbacks.py:416\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    414\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m--> 416\u001b[0m   callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\callbacks.py:1862\u001b[0m, in \u001b[0;36mEarlyStopping.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_epoch \u001b[39m=\u001b[39m epoch\n\u001b[0;32m   1861\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestore_best_weights:\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_weights()\n\u001b[0;32m   1863\u001b[0m \u001b[39m# Only restart wait if we beat both the baseline and our previous best.\u001b[39;00m\n\u001b[0;32m   1864\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbaseline \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_improvement(current, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbaseline):\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\engine\\training.py:2381\u001b[0m, in \u001b[0;36mModel.get_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2375\u001b[0m \u001b[39m\"\"\"Retrieves the weights of the model.\u001b[39;00m\n\u001b[0;32m   2376\u001b[0m \n\u001b[0;32m   2377\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m   2378\u001b[0m \u001b[39m    A flat list of Numpy arrays.\u001b[39;00m\n\u001b[0;32m   2379\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2380\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2381\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Model, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mget_weights()\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\engine\\base_layer.py:1698\u001b[0m, in \u001b[0;36mLayer.get_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1696\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1697\u001b[0m     output_weights\u001b[39m.\u001b[39mappend(weight)\n\u001b[1;32m-> 1698\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mbatch_get_value(output_weights)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\backend.py:3968\u001b[0m, in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   3956\u001b[0m \u001b[39m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   3957\u001b[0m \n\u001b[0;32m   3958\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[39m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   3966\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3967\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 3968\u001b[0m   \u001b[39mreturn\u001b[39;00m [x\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tensors]\n\u001b[0;32m   3969\u001b[0m \u001b[39melif\u001b[39;00m tf\u001b[39m.\u001b[39minside_function():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3970\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\keras\\backend.py:3968\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3956\u001b[0m \u001b[39m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   3957\u001b[0m \n\u001b[0;32m   3958\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[39m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   3966\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3967\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 3968\u001b[0m   \u001b[39mreturn\u001b[39;00m [x\u001b[39m.\u001b[39;49mnumpy() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tensors]\n\u001b[0;32m   3969\u001b[0m \u001b[39melif\u001b[39;00m tf\u001b[39m.\u001b[39minside_function():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3970\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Desktop\\projekty\\ml\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1160\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39;49mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = 1024\n",
    "\n",
    "model = keras.Sequential([\n",
    "  #layers.Dense(n, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), input_shape=[282]), \n",
    "  layers.Dense(n, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "  layers.Dropout(0.5),\n",
    "  layers.Dense(n, activation='relu'),\n",
    "  layers.Dropout(0.5),\n",
    "  layers.Dense(n, activation='relu'),\n",
    "  layers.Dense(n, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mean_squared_logarithmic_error',\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  #X, y,\n",
    "  X_train, y_train,\n",
    "  validation_data=(X_val, y_val),\n",
    "  batch_size=64,\n",
    "  epochs=1000,\n",
    "  callbacks=[early_stopping],\n",
    "  verbose=1,\n",
    ")\n",
    "\n",
    "#history_df = pd.DataFrame(history.history)\n",
    "#history_df.loc[:, ['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19268\\3166724115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mpredictions_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#X_test.drop(columns=\"YearBuilt\", inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#X_test = pd.DataFrame(preprocessor.transform(X_test).toarray())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def make_submission(model, test_data):\n",
    "  predictions = model.predict(test_data)\n",
    "  final_predictions = []\n",
    "  for i in range(len(predictions)):\n",
    "    final_predictions.append(predictions[i][0])\n",
    "  predictions_df = pd.DataFrame(data={\"Id\": range(1461, 1461 + len(test_data)), \"SalePrice\": final_predictions})\n",
    "  predictions_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "X_test = pd.read_csv(\"test.csv\")\n",
    "#X_test.drop(columns=\"YearBuilt\", inplace=True)\n",
    "#X_test = pd.DataFrame(preprocessor.transform(X_test).toarray())\n",
    "X_test = X_test.join(C, how=\"left\", lsuffix=\"YearBuilt\")\n",
    "X_test.drop(columns=\"YearBuilt\", inplace=True)\n",
    "X_test = pd.DataFrame(preprocessor.transform(X_test).toarray())\n",
    "make_submission(model, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "370a9e096d86eb650b3a59711554aeb8c7b73065e0a2dba8d3bdfe46cf71aded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
